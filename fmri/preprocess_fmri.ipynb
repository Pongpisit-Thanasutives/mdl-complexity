{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from os.path import join as oj\n",
    "import tables, numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import data\n",
    "import pickle as pkl\n",
    "from skimage.util import img_as_float\n",
    "from sklearn import metrics\n",
    "import h5py\n",
    "from copy import deepcopy\n",
    "from skimage.filters import gabor_kernel\n",
    "# import gabor_feats\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "import numpy.linalg as npl\n",
    "out_dir = '/scratch/users/vision/data/gallant/vim_2_crcns'\n",
    "from run import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download data\n",
    "Download the raw data for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(datafile, username, password, out_dir):\n",
    "    '''\n",
    "    Params\n",
    "    ------\n",
    "    datafile\n",
    "    '''\n",
    "    \n",
    "    URL = 'https://portal.nersc.gov/project/crcns/download/index.php'\n",
    "    login_data = dict(\n",
    "        username=username,\n",
    "        password=password,\n",
    "        fn=datafile,\n",
    "        submit='Login' \n",
    "    )\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        local_filename = oj(out_dir, login_data['fn'].split('/')[-1])\n",
    "        print(local_filename)\n",
    "        r = s.post(URL, data=login_data, stream=True)\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in tqdm(r.iter_content(chunk_size=1024)):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    \n",
    "uname = 'csinva'\n",
    "pwd = 'password'\n",
    "dset = 'vim-2'\n",
    "fnames = ['Stimuli.tar.gz', 'VoxelResponses_subject1.tar.gz', 'anatomy.zip', 'checksums.md5', 'filelist.txt', 'docs']\n",
    "for fname in fnames:\n",
    "    fname = oj(dset, fname)\n",
    "#     download(fname, uname, pwd, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anatomy.zip    docs          Stimuli.mat     VoxelResponses_subject1.mat\n",
      "checksums.md5  filelist.txt  Stimuli.tar.gz  VoxelResponses_subject1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "ls /scratch/users/vision/data/gallant/vim_2_crcns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9G\t/scratch/users/vision/data/gallant/vim_2_crcns\n"
     ]
    }
   ],
   "source": [
    "!du -sh /scratch/users/vision/data/gallant/vim_2_crcns\n",
    "# next extract the tars\n",
    "# next unzip the zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /scratch/users/vision/data/gallant/vim_2_crcns/*.gz |xargs -n1 tar -xzf # extract the tar files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# responses\n",
    "Look at the responses and save out their standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tables.open_file(oj(out_dir, 'VoxelResponses_subject1.mat'))\n",
    "# f.listNodes # Show all variables available\n",
    "data = f.get_node('/rt')[:] # training responses: 7200 (timepoints) x 73728 (voxels)\n",
    "# plt.imshow(np.isnan(data))\n",
    "roi = f.get_node('/roi/v1lh')[:].flatten() # structure containing volume matrices (64x64x18) with indices corresponding to each roi in each hemisphere\n",
    "v1lh_idx = numpy.nonzero(roi==1)[0]\n",
    "v1lh_resp = data[v1lh_idx] # 494 (v1 voxels) x 7200 (timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot(v1lh_resp[100, :100])\n",
    "plt.xlabel('t')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(v1lh_resp[:200, :200])\n",
    "plt.ylabel('voxels')\n",
    "plt.xlabel('time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tables.open_file(oj(out_dir, 'VoxelResponses_subject1.mat'))\n",
    "xs = []\n",
    "nums = []\n",
    "for x in f.get_node('/roi'):\n",
    "    xs.append(x)\n",
    "    nums.append(np.array(f.get_node(x)).nonzero()[0].sum())\n",
    "# sns.barplot(x=x, y=nums)\n",
    "print([str(x) for x in xs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate error terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73728/73728 [02:59<00:00, 411.69it/s]\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: Mean of empty slice\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "f = tables.open_file(oj(out_dir, 'VoxelResponses_subject1.mat'))\n",
    "rva = np.array(f.get_node('/rva')[:]) # 73728 (voxels) x 10 (trials) x 540 (timepoints)\n",
    "# sigmas = np.nanmean(np.nanstd(rva, axis=1), axis=-1)\n",
    "# out_name = oj(out_dir, f'out_rva_sigmas.h5')\n",
    "# save_h5(sigmas, out_name)\n",
    "\n",
    "# normalized\n",
    "rva_norm = np.empty(rva.shape)\n",
    "for i in tqdm(range(rva.shape[0])):\n",
    "    rva_norm[i] = rva[i] / np.nanstd(rva[i].flatten() + 1e-8) # don't subtract mean bc it doesn't matter\n",
    "#     for j in range(10):\n",
    "#         rva_norm[i, j] = rva[i, j] / np.nanstd(rva[i, j].flatten() + 1e-8) # don't subtract mean bc it doesn't matter\n",
    "sigmas = np.nanmean(np.nanstd(rva_norm, axis=1, ddof=1), axis=-1)\n",
    "# out_name = oj(out_dir, f'out_rva_sigmas_norm.h5')\n",
    "# save_h5(sigmas, out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**normalize responses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resps_name = oj(out_dir, 'VoxelResponses_subject1.mat')\n",
    "for dset in ['rt', 'rv']:\n",
    "    Y = np.array(tables.open_file(resps_name).get_node(f'/{dset}')[:]) # training responses: 73728 (voxels) x 7200 (timepoints)\n",
    "    Y -= np.nanmean(Y, axis=1).reshape(-1, 1) # mean over time dimension\n",
    "    Y /= (np.nanstd(Y, axis=1).reshape(-1, 1) + 1e-8) # std over time dimension\n",
    "    save_h5(Y, oj(out_dir, f'{dset}_norm.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = load_h5(oj(out_dir, 'rt_norm.h5') )\n",
    "Y_test = load_h5(oj(out_dir, 'rv_norm.h5') )\n",
    "Y_test_init = np.array(tables.open_file(resps_name).get_node(f'/rv')[:]) # training responses: 73728 (voxels) x 7200 (timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test[150])\n",
    "plt.plot(Y_test_init[150] * 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.imshow(Y_test_init[:300])\n",
    "plt.ylabel('neurons')\n",
    "plt.xlabel('timepoints')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stimuli\n",
    "Read out the stimuli, and the extracted gabor features from the matlab code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQ = 15\n",
    "DOWNSAMPLE = 2\n",
    "N_TRAIN = 7200\n",
    "N_TEST = 540\n",
    "OFFSET = SAMPLING_FREQ // 2\n",
    "NUM_FEATS = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8100, 3, 128, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = tables.open_file(oj(out_dir, 'Stimuli.mat'))\n",
    "f2.get_node(f'/sv').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**look at an example stimulus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = tables.open_file(oj(out_dir, 'Stimuli.mat'))\n",
    "im = f2.get_node('/st')[100].transpose()\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the relevant stimuli\n",
    "for dset, N in zip(['sv'], [N_TEST]): # 'st', 'sv'\n",
    "    f2 = tables.open_file(oj(out_dir, 'Stimuli.mat'))\n",
    "    ims = np.zeros((N, 128 // DOWNSAMPLE, 128 // DOWNSAMPLE)).astype(np.int)\n",
    "    for i in tqdm(range(N)):\n",
    "        ims[i] = deepcopy(f2.get_node(f'/{dset}')[OFFSET + i * SAMPLING_FREQ].transpose())[::DOWNSAMPLE, ::DOWNSAMPLE].mean(axis=-1)\n",
    "\n",
    "    out_name = oj(out_dir, f'out_{dset}.h5')\n",
    "    save_h5(ims, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert stimuli to feature vectors\n",
    "for dset, N in zip(['sv'], [N_TEST]): # 'st', 'sv'\n",
    "    f = h5py.File(oj(out_dir, f'out_{dset}.h5'), 'r')\n",
    "    feats = np.zeros((N, NUM_FEATS))\n",
    "    for i in tqdm(range(N)):\n",
    "        feats[i] = gabor_feats.all_feats(deepcopy(f['data'][i]))\n",
    "\n",
    "    out_name = oj(out_dir, f'out_{dset}_feats.h5')\n",
    "    save_h5(feats, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize things\n",
    "for dset, N in zip(['st', 'sv'], [N_TRAIN, N_TEST]): # 'st', 'sv'\n",
    "    for suffix in ['', '_feats']:\n",
    "        feats_name = oj(out_dir, f'out_{dset}{suffix}.h5')\n",
    "        data = load_h5(feats_name)\n",
    "        data = data.reshape(data.shape[0], -1).astype(np.float32)\n",
    "        data -= data.mean(axis=1).reshape(-1, 1)\n",
    "        data /= (data.std(axis=1).reshape(-1, 1) + 1e-8)\n",
    "        out_name = oj(out_dir, f'out_{dset}{suffix}_norm.h5')\n",
    "        save_h5(data, out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generate small data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SMALL = 720\n",
    "X_train = np.array(loadmat(oj(out_dir, 'mot_energy_feats_st.mat'))['S_fin'])\n",
    "X_train_small = X_train[:N_SMALL]\n",
    "out_name = oj(out_dir, f'mot_energy_feats_st_small.h5')\n",
    "save_h5(X_train_small, out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**find SVD of features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose the training data\n",
    "'''\n",
    "suffix = '' # _feats\n",
    "X = np.array(h5py.File(oj(out_dir, f'out_st{suffix}.h5'), 'r')['data'])\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "U, s, Vh = npl.svd(X)\n",
    "save_pkl((U, s, Vh), oj(out_dir, f'decomp{suffix}.pkl'))\n",
    "'''\n",
    "\n",
    "# decompose matlab feats\n",
    "'''\n",
    "X = np.array(loadmat(oj(out_dir, 'mot_energy_feats_st.mat'))['S_fin'])\n",
    "U, s, Vh = npl.svd(X)\n",
    "save_pkl((U, s, Vh), oj(out_dir, f'decomp_mot_energy.pkl'))\n",
    "'''\n",
    "\n",
    "# decompose matlab feat small\n",
    "X = load_h5(oj(out_dir, f'mot_energy_feats_st_small.h5'))\n",
    "U, s, Vh = npl.svd(X)\n",
    "save_pkl((U, s, Vh), oj(out_dir, f'decomp_mot_energy_small.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**find eigenvals / eigenvecs of features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvals\n",
    "'''\n",
    "X = np.array(loadmat(oj(out_dir, 'mot_energy_feats_st.mat'))['S_fin'])\n",
    "eigenvals, eigenvecs = npl.eig(X.T @ X)\n",
    "save_pkl((eigenvals, eigenvecs), oj(out_dir, f'eigenvals_eigenvecs_mot_energy.pkl'))\n",
    "'''\n",
    "\n",
    "# eigenvals small\n",
    "X = load_h5(oj(out_dir, f'mot_energy_feats_st_small.h5'))\n",
    "eigenvals, eigenvecs = npl.eig(X.T @ X)\n",
    "save_pkl((eigenvals, eigenvecs), oj(out_dir, f'eigenvals_eigenvecs_mot_energy_small.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**store mat inverses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_params = np.logspace(3, 6, 20).round().astype(int)\n",
    "'''\n",
    "X = np.array(loadmat(oj(out_dir, 'mot_energy_feats_st.mat'))['S_fin'])\n",
    "for reg_param in tqdm(reg_params):\n",
    "    inv = npl.pinv(X.T @ X + reg_param * np.eye(X.shape[1]))\n",
    "    save_pkl(inv, oj(out_dir, f'pinv_mot_energy_st_{reg_param}.pkl'))\n",
    "'''\n",
    "\n",
    "# repeat for small\n",
    "X = load_h5(oj(out_dir, f'mot_energy_feats_st_small.h5'))\n",
    "for reg_param in tqdm(reg_params):\n",
    "    fname = oj(out_dir, f'pinv_mot_energy_st_{reg_param}_small.pkl')\n",
    "    if not os.path.exists(fname):\n",
    "        inv = npl.pinv(X.T @ X + reg_param * np.eye(X.shape[1]))\n",
    "        save_pkl(inv, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(loadmat(oj(out_dir, 'mot_energy_feats_st.mat'))['S_fin'])\n",
    "X_test = np.array(loadmat(oj(out_dir, 'mot_energy_feats_sv.mat'))['S_fin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random\n",
    "from jax.experimental import stax\n",
    "from jax import random\n",
    "from neural_tangents import stax\n",
    "\n",
    "# kernel function\n",
    "init_fn, apply_fn, kernel_fn = stax.serial(\n",
    "    stax.Dense(512), stax.Relu(),\n",
    "    stax.Dense(512), stax.Relu(),\n",
    "    stax.Dense(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training kernel mat\n",
    "kernel = kernel_fn(X, X, 'ntk')\n",
    "fname = oj(out_dir, f'mot_energy_feats_kernel_mat_ntk.pkl')\n",
    "if not os.path.exists(fname):\n",
    "    save_pkl(kernel, fname)\n",
    "    \n",
    "# training kernel mat\n",
    "kernel_test = kernel_fn(X_test, X, 'ntk')\n",
    "fname = oj(out_dir, f'mot_energy_feats_kernel_test_with_train_ntk.pkl')\n",
    "if not os.path.exists(fname):\n",
    "    save_pkl(kernel_test, fname)\n",
    "    \n",
    "# save out eigenvals\n",
    "fname = oj(out_dir, f'eigenvals_eigenvecs_mot_energy_kernel_ntk.pkl')\n",
    "if not os.path.exists(fname):\n",
    "    kernel = load_pkl(oj(out_dir, f'mot_energy_feats_kernel_mat_ntk.pkl'))\n",
    "    eigenvals, eigenvecs = npl.eig(kernel)\n",
    "    save_pkl((eigenvals, eigenvecs), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [46:02<1:56:09, 497.85s/it]"
     ]
    }
   ],
   "source": [
    "# save kernel pinvs\n",
    "reg_params = np.logspace(3, 6, 20).round().astype(int)\n",
    "kernel = load_pkl(oj(out_dir, f'mot_energy_feats_kernel_mat_ntk.pkl'))\n",
    "for reg_param in tqdm(reg_params):\n",
    "    fname = oj(out_dir, f'pinv_mot_energy_kernel_ntk_{reg_param}.pkl')\n",
    "    if not os.path.exists(fname):\n",
    "        inv = npl.pinv(kernel + reg_param * np.eye(kernel.shape[0]))\n",
    "        save_pkl(inv, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to save kernel matrix\n",
    "# need to save test-time kernel mat\n",
    "\n",
    "\n",
    "# save eigenvalues\n",
    "\n",
    "# make new script\n",
    "# need to switch to use Kernel ridge + eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize preprocessed features\n",
    "**load and look at features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(loadmat(oj(out_dir, 'mot_energy_feats_st.mat'))['S_fin'])\n",
    "X_test = np.array(loadmat(oj(out_dir, 'mot_energy_feats_sv.mat'))['S_fin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[0:3].T, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(U, s, Vh) = pkl.load(open(oj(out_dir, f'decomp_mot_energy.pkl'), 'rb'))\n",
    "plt.loglog(sorted(s)[::-1])\n",
    "plt.xlabel('singular values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eigenvals, eigenvecs) = pkl.load(open(oj(out_dir, f'eigenvals_eigenvecs_mot_energy.pkl'), 'rb'))\n",
    "plt.loglog(sorted(eigenvals)[::-1])\n",
    "plt.xlabel('eigenvals')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
