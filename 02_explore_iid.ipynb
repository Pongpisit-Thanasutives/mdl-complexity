{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmlb\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import data\n",
    "import numpy.linalg as npl\n",
    "from scipy.optimize import minimize\n",
    "from postprocess import process_results, aggregate_results, best_ridge\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "save_dir = 'results'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p:\n",
    "    seed = 15\n",
    "    out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/double_descent/test'\n",
    "    dset = 'gaussian' # gaussian\n",
    "    beta_type = 'gaussian' # one_hot\n",
    "    beta_norm = 1\n",
    "    iid = 'iid' # 'iid', 'clustered', 'spike', decay, mult_decay\n",
    "    dset_num = 1 # only matters for pmlb\n",
    "    dset_name = ''\n",
    "    reg_param = -1.0 # -1 use csv\n",
    "    num_features = 100\n",
    "    n_train_over_num_features = 0.75 # this and num_features sets n_train\n",
    "    n_test = 100\n",
    "    noise_std = 1e-1\n",
    "    noise_distr = 'gaussian' # gaussian, t, gaussian_scale_var, thresh\n",
    "    model_type = 'ridge' # mdl_orig, \n",
    "    cov_param = 2\n",
    "    \n",
    "def add_results(p, r, i):\n",
    "    # warning - this reseeds!\n",
    "    p.n_train = int(p.n_train_over_num_features * p.num_features)\n",
    "    X_train, y_train, X_test, y_test, betastar = \\\n",
    "        data.get_data_train_test(n_train=p.n_train, n_test=p.n_test, p=p.num_features, \n",
    "                            noise_std=p.noise_std, noise_distr=p.noise_distr, iid=p.iid, # parameters to be determined\n",
    "                            beta_type=p.beta_type, beta_norm=p.beta_norm, \n",
    "                            seed_for_training_data=p.seed, cov_param=p.cov_param)\n",
    "\n",
    "    eigenvals, eigenvecs = npl.eig(X_train.T @ X_train)\n",
    "    var = p.noise_std**2\n",
    "\n",
    "    def calc_thetahat(l):\n",
    "        inv = npl.pinv(X_train.T @ X_train + l * np.eye(p.num_features))\n",
    "        return inv @ X_train.T @ y_train\n",
    "\n",
    "    def mdl1_loss(l):\n",
    "        thetahat = calc_thetahat(l)\n",
    "        mse_norm = npl.norm(y_train - X_train @ thetahat)**2 / (2 * var)\n",
    "        theta_norm = npl.norm(thetahat)**2 / (2 * var)\n",
    "        eigensum = 0.5 * np.sum(np.log((eigenvals + l) / l))\n",
    "        return (mse_norm + theta_norm + eigensum) / y_train.size\n",
    "\n",
    "    opt_solved = minimize(mdl1_loss, x0=1e-10)\n",
    "    lambda_opt = opt_solved.x\n",
    "    thetahat = calc_thetahat(lambda_opt)\n",
    "    r['mse_norm'][i] = npl.norm(y_train - X_train @ thetahat)**2 / (2 * var)\n",
    "    r['theta_norm'][i] = npl.norm(thetahat)**2 / (2 * var)\n",
    "    r['eigensum'][i] = 0.5 * np.sum(np.log((eigenvals + lambda_opt) / lambda_opt))\n",
    "    r['mse_test'][i] = np.mean(np.square(y_test - X_test @ thetahat))\n",
    "    r['loss_val'][i] = opt_solved.fun\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vary p/n\n",
    "**looks at how MDL-COMP varies as d/n varies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/accounts/projects/vision/.local/lib/python3.7/site-packages/ipykernel_launcher.py:47: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "16it [00:10,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "n_train_over_num_features_list = np.array([1e-2, 5e-2, 1e-1, 0.5, 0.75, 0.9, 1,\n",
    "                                  1.2, 1.5, 2, 5, 7.5, 1e1, 2e1, 4e1, 1e2])\n",
    "n = n_train_over_num_features_list.size\n",
    "r = {\n",
    "    'mse_norm': np.zeros(n),\n",
    "    'theta_norm': np.zeros(n),\n",
    "    'eigensum': np.zeros(n),\n",
    "    'mse_test': np.zeros(n),\n",
    "    'loss_val': np.zeros(n)\n",
    "}\n",
    "\n",
    "for i, n_train_over_num_features in tqdm(enumerate(n_train_over_num_features_list)):\n",
    "    p.n_train_over_num_features = n_train_over_num_features\n",
    "    # p.n_train = int(n_train_over_num_features * p.num_features)\n",
    "    r = add_results(p, r, i)\n",
    "    \n",
    "# r['loss_val'] = r['mse_norm'] + r['theta_norm'] + r['eigensum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fig complexity vs d/n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r['n_train_over_num_features_list'] = n_train_over_num_features_list\n",
    "r['num_features'] = p.num_features\n",
    "\n",
    "plt.figure(figsize=(4, 2.5))\n",
    "# plt.axhline(df.mse_zero.values[0], lw=4, color='gray', alpha=0.4, label='trivial')\n",
    "plt.title('A', fontweight='bold', loc='left')\n",
    "#         plt.plot(curve.loss_val, curve.mse_test, **kwargs) #np.square(curve.bias) + curve['var'], **kwargs)\n",
    "plt.ylabel('MDL-COMP')\n",
    "plt.xlabel('$d / n$') #\\n(Number of features / Number of training points)')\n",
    "plt.plot(1/r['n_train_over_num_features_list'],\n",
    "         r['loss_val']) # / r['n_train_over_num_features_list'] / r['num_features'])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(oj(save_dir, 'fig_iid_comp.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**further break down the complexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_n(r):\n",
    "    plt.figure(dpi=300)\n",
    "    def norm(x):\n",
    "        return x / n_train_over_num_features / p.num_features\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['loss_val']), label='loss')\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['mse_norm']), label='mse_norm')\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['theta_norm']), label='theta_norm')\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['eigensum']), label='eigensum')\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['mse_test']), label='mse_test')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('p/n')\n",
    "    plt.ylabel('all term divided by n_train')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "plot_p_n(r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vary design\n",
    "**this section varies the design of the data matrix and sees how the complexity varies (not shown in the main paper)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_param_list = np.logspace(start=0, stop=2, num=10) #[1e-2, 5e-2, 1e-1, 0.5, 0.75, 0.9, 1, 1.2, 1.5, 2, 5, 7.5, 1e1, 2e1, 4e1, 1e2])\n",
    "# cov_param_list = np.array([1e-2, 5e-2, 1e-1, 0.5, 0.75, 0.9, 1, 1.2, 1.5, 2, 5, 7.5, 1e1, 2e1, 4e1, 1e2])\n",
    "n = cov_param_list.size\n",
    "p.num_features = 100\n",
    "p.n_train_over_num_features = 0.75\n",
    "p.iid = 'lin_decay'\n",
    "r = {\n",
    "    'mse_norm': np.zeros(n),\n",
    "    'theta_norm': np.zeros(n),\n",
    "    'eigensum': np.zeros(n),\n",
    "    'mse_test': np.zeros(n),\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for cov_param in tqdm(cov_param_list):\n",
    "    p.cov_param = cov_param\n",
    "    r = add_results(p, r, i)\n",
    "    i += 1\n",
    "r['loss_val'] = r['mse_norm'] + r['theta_norm'] + r['eigensum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cov_param(r):\n",
    "    plt.figure(dpi=300)\n",
    "    R, C = 1, 2\n",
    "    def norm(x):\n",
    "        return x / p.n_train_over_num_features / p.num_features\n",
    "    \n",
    "    plt.subplot(R, C, 1)\n",
    "    \n",
    "#     for measure in ['loss_val']: ## measures:\n",
    "    # plt.loglog(1/n_train_over_num_features_list, norm(r[measure]), label=measure)\n",
    "    plt.loglog(norm(r['loss_val']), norm(r['mse_test']), '.')\n",
    "#     plt.xlim([50, 100])\n",
    "#         plt.yscale('log')\n",
    "#         plt.xscale('log')\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel('MDL-COMP')\n",
    "    plt.ylabel('Test MSE')\n",
    "    \n",
    "    plt.subplot(R, C, 2)    \n",
    "    measures = ['loss_val', 'mse_norm', 'theta_norm', 'eigensum', 'mse_test']\n",
    "\n",
    "    plt.loglog(cov_param_list, norm(r['loss_val']), label='MDL-COMP')\n",
    "    plt.loglog(cov_param_list, norm(r['mse_norm']), label='Train MSE Term')\n",
    "    plt.loglog(cov_param_list, norm(r['loss_val'] - r['mse_norm']), label='Normalization Terms')\n",
    "    # for measure in measures:\n",
    "        \n",
    "    plt.xlabel('Eigenvalue decay factor')\n",
    "    plt.ylabel('Measure')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "\n",
    "plot_cov_param(r)\n",
    "plt.savefig(oj(save_dir, 'fig_design_vary.pdf'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
