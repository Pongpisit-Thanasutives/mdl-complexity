{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmlb\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import data\n",
    "import numpy.linalg as npl\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "save_dir = 'results'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p:\n",
    "    seed = 15\n",
    "    out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/double_descent/test'\n",
    "    dset = 'gaussian' # gaussian\n",
    "    beta_type = 'gaussian' # one_hot\n",
    "    beta_norm = 1\n",
    "    iid = 'iid' # 'iid', 'clustered', 'spike', decay, mult_decay\n",
    "    dset_num = 1 # only matters for pmlb\n",
    "    dset_name = ''\n",
    "    reg_param = -1.0 # -1 use csv\n",
    "    num_features = 100\n",
    "    n_train_over_num_features = 0.75 # this and num_features sets n_train\n",
    "    n_test = 100\n",
    "    noise_std = 1e-1\n",
    "    noise_distr = 'gaussian' # gaussian, t, gaussian_scale_var, thresh\n",
    "    model_type = 'ridge' # mdl_orig, \n",
    "    cov_param = 2\n",
    "    \n",
    "def add_results(p, r, i):\n",
    "    # warning - this reseeds!\n",
    "    p.n_train = int(p.n_train_over_num_features * p.num_features)\n",
    "    X_train, y_train, X_test, y_test, betastar = \\\n",
    "        data.get_data_train_test(n_train=p.n_train, n_test=p.n_test, p=p.num_features, \n",
    "                            noise_std=p.noise_std, noise_distr=p.noise_distr, iid=p.iid, # parameters to be determined\n",
    "                            beta_type=p.beta_type, beta_norm=p.beta_norm, \n",
    "                            seed_for_training_data=p.seed, cov_param=p.cov_param)\n",
    "\n",
    "    eigenvals, eigenvecs = npl.eig(X_train.T @ X_train)\n",
    "    var = p.noise_std**2\n",
    "\n",
    "    def calc_thetahat(l):\n",
    "        inv = npl.pinv(X_train.T @ X_train + l * np.eye(p.num_features))\n",
    "        return inv @ X_train.T @ y_train\n",
    "\n",
    "    def mdl1_loss(l):\n",
    "        thetahat = calc_thetahat(l)\n",
    "        mse_norm = npl.norm(y_train - X_train @ thetahat)**2 / (2 * var)\n",
    "        theta_norm = npl.norm(thetahat)**2 / (2 * var)\n",
    "        eigensum = 0.5 * np.sum(np.log((eigenvals + l) / l))\n",
    "        return (mse_norm + theta_norm + eigensum) / y_train.size\n",
    "\n",
    "    opt_solved = minimize(mdl1_loss, x0=1e-10)\n",
    "    lambda_opt = opt_solved.x\n",
    "    thetahat = calc_thetahat(lambda_opt)\n",
    "    r['mse_norm'][i] = npl.norm(y_train - X_train @ thetahat)**2 / (2 * var)\n",
    "    r['theta_norm'][i] = npl.norm(thetahat)**2 / (2 * var)\n",
    "    r['eigensum'][i] = 0.5 * np.sum(np.log((eigenvals + lambda_opt) / lambda_opt))\n",
    "    r['mse_test'][i] = np.mean(np.square(y_test - X_test @ thetahat))\n",
    "    r['loss_val'][i] = opt_solved.fun\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vary p/n\n",
    "**looks at how MDL-COMP varies as d/n varies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/accounts/projects/vision/.local/lib/python3.7/site-packages/ipykernel_launcher.py:47: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "16it [00:09,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "n_train_over_num_features_list = np.array([1e-2, 5e-2, 1e-1, 0.5, 0.75, 0.9, 1,\n",
    "                                  1.2, 1.5, 2, 5, 7.5, 1e1, 2e1, 4e1, 1e2])\n",
    "n = n_train_over_num_features_list.size\n",
    "r = {\n",
    "    'mse_norm': np.zeros(n),\n",
    "    'theta_norm': np.zeros(n),\n",
    "    'eigensum': np.zeros(n),\n",
    "    'mse_test': np.zeros(n),\n",
    "    'loss_val': np.zeros(n)\n",
    "}\n",
    "\n",
    "for i, n_train_over_num_features in tqdm(enumerate(n_train_over_num_features_list)):\n",
    "    p.n_train_over_num_features = n_train_over_num_features\n",
    "    # p.n_train = int(n_train_over_num_features * p.num_features)\n",
    "    r = add_results(p, r, i)\n",
    "    \n",
    "# r['loss_val'] = r['mse_norm'] + r['theta_norm'] + r['eigensum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fig complexity vs d/n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAADQCAYAAADcQn7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAc5klEQVR4nO3dd3xUdbrH8c9DCiEQQi9SpIogKKGIZQVkLaCLBRvNiqCu9e5a7xZ2XV13XV1dG14UVlAEBVFpinoV9bKIdCQ06RDESAmkkP7cP84gQ0gyKXNypjzv12temVPmnO+M48OZ3znn9xNVxRhj3FDL6wDGmMhlBcYY4xorMMYY11iBMca4xgqMMcY1VmCMMa6xAmOMcY0VmADEsUNE1Pfo6nUmY8KFFZjALgBO9Zu+0asgxoQbKzCBjfb9XeX7O1JExKswxoQTKzDlEJHawLW+yd8Ch3COZvp7FsqYMGIFpnyXAw2BdOBLYJ5v/ugyX2GM+ZkVmPIdKyRzVbUYeN83fZ3v6MYYUw6xu6lLJyINgH1AWYXkOlWdVYORjAk7sV4HCGHX4xSXI8AXfvO7AZ1xziZZgTGmHHYEUwYR+QrnFPU/VPVhv/kDgEVAAdBSVQ94k9CY0GcFxhjjGmvkNca4xgqMMcY1VmCMMa6xAmOMcY0VmDIMHjxYgXIfS5YsCbhOKD7CNXc4Z4+C3KWyAlOG/fv3B1wnLy+vBpIEX7jmhvDNHq25rcAYY1xjBcYY4xorMMYY11iBMcaUKSu/zPbbComqAiMidUVkioi8JiKjvM5jTKhSVZ7/bDOPfJ3D7oM5Vd5OjRcYEUkQkW9FZI2IpIrIn6uxrckiki4i60pZNlhENonIFhF51Dd7GDBLVccCV1R1v8ZEstyCIu6bsZrnP/uenk1jaVa/6l0feXEEkwcMUtWzgJ7AYBE5x38FEWkmIkkl5nUqZVtvAINLzhSRGOBlYAhO9wojRKQb0BrY7VutqJrvw5iIk34klxsmfsO8tXt5ZPDp3N4jntqxMVXeXo0XGHVk+SbjfI+SP/QGAB8c6zVORMYCL5ayra+Ag6Xs5mxgi6puU9V8YAZwJbAHp8hAlP08NCaQ1L2HufLlxWzel8mro3tz18COVLd/e0/+JxORGBFZjdPX7aequtR/uarOBBYC7/jaSm4DrqvELlpx/EgFnMLSCpgNXCMiE4C5ZWQbKiITDx8+XIndGRPePkndx3WvLgFg5p3ncukZLYKyXU8KjKoWqWpPnKOJs0WkeynrPA3kAhOAK/yOeqqz32xVvVVV71LVaWWsM1dVxyUnJ1d3d8aEPFVlwqKt3PHWCjo3T+LDu8+ne6vgffc9/Zmgqhk43VGW1o5yAdAdp6Pt8ZXcdBrQxm+6tW+eMcYnr7CIB2eu5e8fb+TyHi15Z9w5NKufENR9eHEWqamvQ21EpA5wMbCxxDopwEScdpNbgcYi8kQldrMM6Cwi7UUkHhgOzAlGfmMiwYGsPEa/vpT3Vu7hgYs68+KIFBLiqt6YWxYvOv1uCUzxnempBbyrqvNKrJMIXK+qWwFE5CbglpIbEpHpwECgiYjsAcar6iRVLRSRe3DacWKAyaqa6tYbMiacbP4xkzFTlpF+JI8XR6Qw9KxTXNtXjRcYVV0LpARYZ3GJ6QLgtVLWG1HONhYAC6oY05iI9MWmdO57exUJ8TG8c8e59GzTwNX92bAlxkQBVeXfi3fwxPz1nN6iPq/f3IdTGtRxfb9WYIyJcAVFxYyfk8rbS3dxSbfmPD+8J4nxNfO/vhUYYyJYRk4+v562kv9sPcBdAzvy0CVdqFWrehfPVYYVGGMi1LafshgzZTlph47y7HVncU3v1oFfFGRWYIyJQP/Zsp+7pq0kppYwbWw/+rZr5EkOKzDGRJhpS3cy/sNUOjSty6Sb+9KmUaJnWazAGBMhCouKeXLBBv69eAcXdmnKCyNSSEqI8zSTFRhjIsCR3ALum76KRZt+4rbz2/O7y7sSU4ONuWWxAmNMmNt1IIcxU5axfX82f726ByP7tfU60s+swBgTxr7dfpA731pBUbEy9bazOa9TE68jncAKjDFhataKPTw2ey1tGiYy6Za+tG9S1+tIJ7ECY0yYKS5Wnl64iVe/3Mr5nRrzysjeJCd625hbFiswxoSR7LxCHnhnNZ+u/5FR/drypyvOIC4mdHt/tQJjTJjYm3GUMVOWs2nfEf40tBs3n9eu2n3mus0KjDFhYNWuQ4yduoK8giIm39KXgV2aeR2pQqzAGBPi5qzZy4Mz19CifgLTx/ajc/OkwC8KEVZgjAlRqspzn33PC//7PWe3a8SrN/amUd14r2NVihUYY0JQUbHy23dX88HqvVzbuzVPXt29WgOgecUKjDEhprhYeXjWWj5YvZcHLzmNuy/sFPKNuWWxAmNMCFFV/vDhOt5buYffXHwa9wzq7HWkaomqAiMidYFXgHxgUVmDrxnjBVXlL/M2MG3pLu4a2JF7B5U2HHt48WJcpDYi8oWIrBeRVBG5vxrbmiwi6SKyrpRlg0Vkk4hsEZFHfbOHAbNUdSxwRVX3a4wbnv1kM5MXb+eW89rx8KVdwvZnkT8vLgEsBH6rqt2Ac4C7RaSb/woi0kxEkkrMK62cv0Hpo0LGAC8DQ4BuwAjfPlpzfMzqomq+D2OC5qXPv+elL7Yw4uy2jB/aLSKKC3hQYFT1B1Vd6XueCWzAGZje3wDgAxGpDSAiY4EXS9nWV8DBUnZzNrBFVbepaj4wA2eUyD04RQbKeO8iMlREJh4+fLjS782Yqnj9620888lmhqW04smrukdMcQGPx6YWkXY4g7At9Z+vqjNxRmV8R0RGAbcB11Vi0604fqQCTmFpBcwGrhGRCcDc0l6oqnNVdVxycvAGADemLG9+s5Mn5m/g8h4tefraM2u0x/+a4Fkjr4jUA94DHlDVIyWXq+rTIjIDmAB0VNWs6u5TVbNxxro2xnOzVuzhDx+s46KuzXjuhp7EhvBNi1XlyTsSkTic4jJNVWeXsc4FQHfgfWB8JXeRBrTxm27tm2dMSJi7Zi8Pz1rDBZ2b8NLIXsTHRl5xAW/OIgkwCdigqv8sY50UYCJOu8mtQGMReaISu1kGdBaR9iISDwwH5lQvuTHBsTB1Hw+8s5o+7Rox8cY+JMSF3xW6FeVF2TwfuBEYJCKrfY/LSqyTCFyvqltVtRi4CdhZckMiMh1YAnQRkT0iMgZAVQuBe3DacTYA76pqqntvydSkw0cLOJofnicBF21K5963V9GjVTKTb+lLnfjILS7gQRuMqv4fUG5LlqouLjFdALxWynojytnGAmBBFWOaEKOqTF2ykze/OcrWhZ+gCi2TE2jXuC6nNk6kUd14GibG0yAxjoaJ8TSsG0eDRGdecp24kOhh/z9b93PHmyvo3LweU247m3q1I/8614DvUER6Ap2AVFXd4H4kY072/qo0xs9JpW1SLe4b1JnYWsL2A9ls35/NZxvSOZSTT1Gxlvn6uvEx1EuIpW7tWOr5HnV//htDvdpx1Ksdc/LyBL/n8c66VWmM/f5QEc99vpy2jRJ5c0w/kuuEZheXwVZugRGRPwKjgRXA0yLylKqedCRhjJsycvJ5cv4GUto24N6u+Qy68LST1lFVMvMKycgu4FBOPody8snIKfj5b1ZeIVm5hWTlF5Kd5zx2H8whO7+Q7LwisnILyS8qrlCehLhaJxShk4uWU7CcwhWLCPxzRS4tGtRl2th+YdflQnUEOoK5Aeipqjki0hj4mFJ+qhjjpr9/vJGMowW8dXUPfty0stR1RIT6CXHUT4ijbeOqDZWaX1hMdl6hU4x8RSgz73hByvIVouz8wp8L1rH1fzySy7Zj6+QVkFtwYrFqUkeYdns/miUlVClbuApUYPJUNQdAVQ+ISGSeSzMha/mOg0z/djfj+nega8v6/LjJvX3Fx9YiPjaehkE4wigsKiY7v+jnArR93XJOaVAnCCnDS6AC00FEjp3eFaCj3zSqajcMGtcUFBXzu/fXcUpyAvf/Mry6LYiNqUVynVo/t7Xs3eB9I7MXAhWYK0tMP+NWEGNKmvjVNjb9mMlrN/WhbhSccYlE5f5XU9UvayqIMf7eXrqLfyzcxGU9WnBxt+ZexzFVFOgs0trylqvqmcGNYwxMXbKDP36YyqDTm/HP63t6HcdUQ6DjzmJAgbdx7j4+6noiE9Um/992Hp+3nou6NuflUSlh2dG1Oa7cs0Kq2hMYAdTDKTJPAmcAaap60qX7xlTHxK+28vi89Qw+owWvjOplxSUCBDztrKobVXW8qvbCOYqZCvyX68lMVFmYuo+/LtjI5T1a8uLIlIi9uzjaVORWgVY4dyNfDRzCKS7vu5zLRJHsvEL+PCeV01sk8fzwniE9mLupnECNvF8CScC7ON0mHPAtiheRRqpaWneVxlTKC59/z97DubwwIsWKS4QJdARzKk4j7x2+h3L8TmgFOrgXzUSDTfsymfT1dq7v05o+7Rp5HccEWaDrYNrVUA4ThVSVP3ywjnoJsTw6pKvXcYwLKtIGEw+Mwjl7BJAKvK2qeW4GM5HvvZVpfLvjIH8b1iOq7jCOJuX+4PWNJbQeGAjs8j0GAqkickbZrzSmfBk5+Ty1YAO92jbg+j5tAr/AhKVARzAvAnep6qf+M0XkIuAl4EK3gpnI9o+FmziUk8+bY/pF3FAd5rhATfatShYXAFX9DGjhTiQT6VbvzuDtb3dxy3nt6XZKfa/jGBcFKjC1jo2u6E9EEvBwTCUTvoqKld9/8B3NkmrzXxeHVxcMpvICFZipwHsicuqxGb7RGN8F3nQvlolUM5fvZl3aEX53eTeSEqKjX9poFug09RMicg/wtYgc64cwG3hGVU8aK9qY8mTmFvDMJ5vpc2pDhp7Z0us4pgYE/Jmjqi8BL4lIkm860/VUJiK9smgr+7PymHRzn4ga4N2ULdBp6t/4DWaWeay4iMgYEXmgJgKayLD7YA6Tvt7OsJRWnNWmgddxTA0J1AYzCqcdpqQ3gduCH8dEqr99tJGYWsJDg7t4HcXUoEAFJtY3quIJVDWfAKMzGnPMt9sPMv+7H7hzQEdaJkdfz/rRrCKnqU/qELW0ecaUprhY+cu89bRMTmBcf7s3NtoEKjD/AOaLyAARSfI9BgLzsBEGTAXMXpXGd2mHeWTw6RE/0Ls5WaDT1FNF5CfgcaA7ThcNqcAfVfWjGshnwlh2XiFPf7yRnm0acMVZp3gdx3igIqepPwKsmJhK+58vt5KemceE0b3tfqMoVenuw0Sk9MGBjfGTlnGU//lqG1ecdQq9T23odRzjkar0T2j/FJmA/v7RRgAeGXK6x0mMl6pSYOYHPYWJKCt2HmLOmr2M69+BVlE44Ls5rtIFRlV/DyAii4Mfx4S7Y6elmyXV5s4BHb2OYzxWnS7c2wYthYkYc9bsZfXuDB66tIsNWG+qVWA0aClMRDiaX8TfP95I91b1uaZXa6/jmBAQaFykYWUtAuzHtTnBxK+28cPhXP41PMVOSxsg8HUwQ8tZNi+YQUx423c4l1e/3MplPVpwdnsb38g4Al3Je2tNBTHh7emFGykqVh6z8Y2Mn4qMi9QFGAccu6BhAzBRVTe7GcyEjzW7M5i9Mo07B3SkTaPEwC8wUSNQh1PnAouALGAi8BpOl5mLROQc19MFiYjUFZEpIvKaiIzyOk8kUXVOSzepF8/dF9ppaXOiQGeR/giMUNXxqvqhqn6gquOBEcB49+OVTUQmi0i6iKwrMX+wiGwSkS0i8qhv9jBglqqOBa6o8bARbP53P7B85yEevKSLdeJtThKowHRU1UUlZ6rql3g/8P0bwGD/GSISA7wMDAG6ASN8o1O2Bnb7ViuqwYwRLbegiKcWbKRry/pcZ6MzmlKIatmXs4jIClXtXcaylaray7VkFeAbQmWeqnb3TZ8L/ElVL/VNP+ZbdQ9wSFXnicgMVR1exvbG4bQ30bx5894zZswod/9ZWVnUq1cvGG+lRgUr97yt+cz6voBH+ibQtXHN9PUS7Z95Tato7oEDB5Z6XUKgRt42IvJCKfMFaBU4Xo1rxfEjFXAKSz/gBZyRES4H5pb1YlWdiNPWRJ8+fXTgwIHl7mzRokUEWicUBSN3emYud3++iIu7Neeua/oEJ1gFRPNn7oXq5g5UYB4qZ9nyKu+1hqlqNmCn3IPo2YWbyS8q5r8vs9PSpmyBroOZUlNBgiQN8G8MaO2bZ4JoXdph3l2xm9t/0Z72Tep6HceEsEC3Cswpb7mqhtoZmWVAZxFpj1NYhgMjvY0UWY6dlm6YGM89g2xsaVO+QD+RzsVp05gOLCWEOpsSkenAQKCJiOwBxqvqJN9QtwuBGGCyqqZ6GDPiLEz9kaXbD/KXq7qTXMdOS5vyBSowLYCLca57GYnT2dT0UPifVlVHlDF/AbCghuNEhbzCIv66YAOnNa/HiL52WtoEVu51MKpapKofq+rNwDnAFpyreO+pkXQmpLyxeAe7Dubw+8u7ERtTnZ4+TLSoyL1ItYHLcY5i2uGc8n3f3VjeEZGhwNBOnTp5HSWk7M/K46XPtzDo9Gb0P62p13FMmAh0L9JUYAnQC/izqvZV1b+oasSemVHVuao6Ljk52esoIaO4WHn0vbUcLSiy09KmUgIdwYzGubnxfuA+kZ/beAVQVa3vYjYTIp77bDOfbUjnz1ecQadm4Xc1qvFOoOtg7Id2lJu/9gde/HwLN/Rpw03nnup1HBNmrICYMqXuPcyDM9fQ+9SGPH7VGfgdwRpTIVZgTKkOZOUxbuoKkuvEMWF0L2rH2sD1pvJsXAlzkoKiYn49bSX7s/KYeee5NEtK8DqSCVNWYMxJHp+7nqXbD/L8DT05s3UDr+OYMGY/kcwJ3l66ize/2ckd/TtwVUoo9shhwokVmBJEZKiITDx8+LDXUWrcsh0HGT9nHQNOa8rDg23QelN9VmBKiNYL7XYdyOGut1bQumEiLwxPIcYGTjNBYG0wUWxvxlEWpu7jo3X7WL7jIInxscwY15vkRLtL2gSHFZgok51XyIJt+TyXupg1uzMA6NI8iXsGdWZYSivaWQdSJoiswESR4mLl3umr+HxzAWe2Vh66tAtDuregQ1O7/N+4wwpMFHll0RY+35jO6K7xPHHzL7yOY6KANfJGia+//4lnP93MVT1P4Zdt7d8VUzOswESBvRlHuX/Gajo3q8dfh/Wwe4pMjbECE+HyC53L/vMLi5kwujeJ8Xb0YmqOFZgSIu1Cuyfnr2f17gyevvZMOlpjrqlhVmBKiKQL7T5cncaUJTu5/RftuaxHS6/jmChkBSZCbf4xk0ff+46+7RryyBC77N94wwpMBMrKK+TOt1ZQt3YsL43sRZyNAGA8Yi1+EUZVeWTWWnYeyGHa7f1oXt/6cjHesX/aIszkxTuY/90PPHxpF87p0NjrOCbKWYGJIMt2HOSpBRu4pFtzxvXv4HUcY6zARIqfMvO4e9pKWjeswzPXn2UX05mQEFUFRkQ6iMgkEZnldZZgKiwq5t7pKzmSW8CE0b2pn2DdLZjQ4GqBEZEGIjJLRDaKyAYRObeK25ksIukisq6UZYNFZJOIbBGRR8vbjqpuU9UxVckQyp79dDPfbDvIk1f1oGtLGwvPhA63zyL9C/hYVa8VkXgg0X+hiDQDjqpqpt+8Tqq6pcR23gBeAqaWeH0M8DJwMbAHWCYic4AY4KkS27hNVdOr/5ZCyyep+5iwaCsj+7Xlmt6tvY5jzAlcKzAikgz0B24BUNV8IL/EagOAO0XkMlXNE5GxwDBgiP9KqvqViLQrZTdnA1tUdZtvnzOAK1X1KeBXVcw9FBjaqVOnqry8Ru3Yn81vZ67hzNbJ/PFX3byOY8xJ3PyJ1B74Cfi3iKwSkddF5ITu0lR1JrAQeEdERgG3AddVYh+tgN1+03t880olIo1F5FUgRUQeK22dcLlV4GB2PndNW0lMLeHlkb1IiLOB0UzocfMnUizQC7hXVZeKyL+AR4E/+K+kqk/7jjwmAB1VNcutQKp6ALjTre27La+wiM83pDN7VRqLNqVTVKxMuqUvbRolBn6xMR5ws8DsAfao6lLf9CycAnMCEbkA6A68D4wH7qnEPtKANn7TrX3zIoaqsmLnId5bmcb8tXs5kltIs6Ta3HJeO67t3YYuLZK8jmhMmVwrMKq6T0R2i0gXVd0E/BJY77+OiKQAE3HaS7YD00TkCVX9fQV3swzoLCLtcQrLcGBk0N6Eh3bsz2b2qjQ+WJXGroM51ImLYXD3Flyd0orzOzWxYUVMWHD7LNK9OEUjHtgG3FpieSJwvapuBRCRm/A1CvsTkenAQKCJiOwBxqvqJFUtFJF7cNpxYoDJqprq1ptx26HsfOat3cvsVWms2pWBCJzfsQkPXNSZS89oQd3aduuYCS+ufmNVdTXQp5zli0tMFwCvlbLeiHK2sQBYUI2YNa6wqJjM3EIycws5klvAzgM5fLg6jS82pVNQpJzeIonHhpzOlT1b0SLZblY04cv+Sayi9CO57M4sZtmOg2TmFnDkaKHz11c0MnMLOXK0wFdInPmZvvk5+UUnba+pr13l6pTWdDvFLpYzkcEKTBX9etpKlu88CouXnLQsPrYW9RNiqZ8QR1JCLEkJcbRITiCpdhz16zjTSX7LG9erzVmtk4m1fltMhLECU0X3/rIz365cwzm9zyIpIY76CccLh12TYozDCkwVDTitKbo3lgs6N/U6ijEhy47JjTGusQJjjHGNFRhjjGuswJQQaQOvGeMlUVWvM4QkEfkJ2AkkA8eqzbHnx/42AfZXYfP+26zM8pLzy5sO5dwVyVrWc6+zh+tn7nbu/ao6+KS5qmqPch7AxJLP/f4ur+42K7O85PzypkM5d0WylvMe7DMPg9zHHvYTKbC5pTyfW9qKVdxmZZaXnF/edCjnLjmvss+rIto/85rODdhPpGoRkeWqWua9VqEqXHND+GaP1tx2BFM9E70OUEXhmhvCN3tU5rYjGGOMa+wIxhjjGiswxhjXWIExxrjGCowxxjVWYFwiIleJyGsi8o6IXOJ1nooKp/G7RaSuiEzxfc6jvM5TGeH0Ofur9Pe6OlfpReoDmAykA+tKzB8MbAK2AI9WcFsNgUlhmHtWqH/2wI3AUN/zd8Lxe+PV5xyE3BX6Xnv6xkL1gTPkbS//Dxxn1IKtQAcgHlgDdAN6APNKPJr5ve5ZoFcY5vaqwFTmPTwG9PSt83Y4fW+8/pyDkLtC32vr0a4UWvpY2JUaB1tEBPgb8JGqrnQ3sSMYub1WmfeAM7hfa2A1IfBzv5LZ1xMiKpNbRDZQie+15/9RwkilxsHGGRPqIuBaEfFyuNqgj9/tgbLew2zgGhGZQJDunXFBqdlD9HP2V9ZnXqnvtR3BuERVXwBe8DpHZWkYjd+tqtmcPJhfWAinz9lfZb/XdgRTceE6Dna45vYXzu8hXLMHJbcVmIr7eRxs31C4w4E5HmeqiHDN7S+c30O4Zg9Obq9bsEPxAUwHfgAKcH57jvHNvwzYjNO6/juvc0ZK7kh5D+Ga3c3cdje1McY19hPJGOMaKzDGGNdYgTHGuMYKjDHGNVZgjDGusQJjjHGNFRhjjGuswBhjXGMFxoQ8EXldRH7le/6qiJzvdSZTMVZgTDhIwenzBeAc4BsPs5hKsO4aTMgRkdNwunFMBmYALVR1j4h0BTarapGIzMbptKk/0A64TVU/8yqzKZ0dwZiQIiK1gfeB36hqD5xOjjb6Fg8BPvY97wFkqGp/4H4grDr9jhZ2BGNCzVXAclX91jedCuT6nl8K3CoiiThHN8/55scBGTWa0lSIHcGYUNMDWOE33RtY7SsqDVR1L06H3ytUtci3zpnAupqNaSrCCowJNQeA7gAi0hsYgdOj/YXAF751enC80RecArO2BjOaCrKfSCbUvAksEJHVOGPyZOA05o4Fjg1S1gNY6vea7tgRTEiyDqdMWBCRlUA/VS3wOoupOCswxhjXWBuMMcY1VmCMMa6xAmOMcY0VGGOMa6zAGGNcYwXGGOMaKzDGGNf8P/qXweFWNBU/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r['n_train_over_num_features_list'] = n_train_over_num_features_list\n",
    "r['num_features'] = p.num_features\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "# plt.axhline(df.mse_zero.values[0], lw=4, color='gray', alpha=0.4, label='trivial')\n",
    "plt.title('A', fontweight='bold', loc='left')\n",
    "#         plt.plot(curve.loss_val, curve.mse_test, **kwargs) #np.square(curve.bias) + curve['var'], **kwargs)\n",
    "plt.ylabel('MDL-COMP')\n",
    "plt.xlabel('$d / n$') #\\n(Number of features / Number of training points)')\n",
    "plt.plot(1/r['n_train_over_num_features_list'],\n",
    "         r['loss_val']) # / r['n_train_over_num_features_list'] / r['num_features'])\n",
    "ax = plt.subplot(111)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(oj(save_dir, 'fig_iid_comp.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**further break down the complexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_n(r):\n",
    "    plt.figure(dpi=300)\n",
    "    def norm(x):\n",
    "        return x / n_train_over_num_features / p.num_features\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['loss_val']), label='loss')\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['mse_norm']), label='mse_norm')\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['theta_norm']), label='theta_norm')\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['eigensum']), label='eigensum')\n",
    "    plt.plot(1/n_train_over_num_features_list, norm(r['mse_test']), label='mse_test')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('p/n')\n",
    "    plt.ylabel('all term divided by n_train')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "plot_p_n(r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vary design\n",
    "**this section varies the design of the data matrix and sees how the complexity varies (not shown in the main paper)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_param_list = np.logspace(start=0, stop=2, num=10) #[1e-2, 5e-2, 1e-1, 0.5, 0.75, 0.9, 1, 1.2, 1.5, 2, 5, 7.5, 1e1, 2e1, 4e1, 1e2])\n",
    "# cov_param_list = np.array([1e-2, 5e-2, 1e-1, 0.5, 0.75, 0.9, 1, 1.2, 1.5, 2, 5, 7.5, 1e1, 2e1, 4e1, 1e2])\n",
    "n = cov_param_list.size\n",
    "p.num_features = 100\n",
    "p.n_train_over_num_features = 0.75\n",
    "p.iid = 'lin_decay'\n",
    "r = {\n",
    "    'mse_norm': np.zeros(n),\n",
    "    'theta_norm': np.zeros(n),\n",
    "    'eigensum': np.zeros(n),\n",
    "    'mse_test': np.zeros(n),\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for cov_param in tqdm(cov_param_list):\n",
    "    p.cov_param = cov_param\n",
    "    r = add_results(p, r, i)\n",
    "    i += 1\n",
    "r['loss_val'] = r['mse_norm'] + r['theta_norm'] + r['eigensum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cov_param(r):\n",
    "    plt.figure(dpi=300)\n",
    "    R, C = 1, 2\n",
    "    def norm(x):\n",
    "        return x / p.n_train_over_num_features / p.num_features\n",
    "    \n",
    "    plt.subplot(R, C, 1)\n",
    "    \n",
    "#     for measure in ['loss_val']: ## measures:\n",
    "    # plt.loglog(1/n_train_over_num_features_list, norm(r[measure]), label=measure)\n",
    "    plt.loglog(norm(r['loss_val']), norm(r['mse_test']), '.')\n",
    "#     plt.xlim([50, 100])\n",
    "#         plt.yscale('log')\n",
    "#         plt.xscale('log')\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel('MDL-COMP')\n",
    "    plt.ylabel('Test MSE')\n",
    "    \n",
    "    plt.subplot(R, C, 2)    \n",
    "    measures = ['loss_val', 'mse_norm', 'theta_norm', 'eigensum', 'mse_test']\n",
    "\n",
    "    plt.loglog(cov_param_list, norm(r['loss_val']), label='MDL-COMP')\n",
    "    plt.loglog(cov_param_list, norm(r['mse_norm']), label='Train MSE Term')\n",
    "    plt.loglog(cov_param_list, norm(r['loss_val'] - r['mse_norm']), label='Normalization Terms')\n",
    "    # for measure in measures:\n",
    "        \n",
    "    plt.xlabel('Eigenvalue decay factor')\n",
    "    plt.ylabel('Measure')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "\n",
    "plot_cov_param(r)\n",
    "plt.savefig(oj(save_dir, 'fig_design_vary.pdf'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
